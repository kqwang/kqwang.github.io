
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-LTSEJNJV2B"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-LTSEJNJV2B');
  </script>

  <title>Kaiqiang</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Kaiqiang Wang is currently a Postdoctoral fellow at HKU">
  <meta name="keywords" content="Kaiqiang Wang, 王凯强, wang kaiqiang, Kaiqiang, Wang, Deep Learning">
  <meta name="author" content="Kaiqiang Wang" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:888px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-center w3-display-container w3-padding-16">
    <h3><b>
      <img style="width: 80%;max-width: 150px" alt="profile photo" src="images/photo1.png" >
      </h2>Kaiqiang Wang</h2>

    </b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#biography" class="w3-bar-item w3-button">Biography</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
<!--    <a href="#projects" class="w3-bar-item w3-button">Projects</a>-->
<!--    <a href="#talks" class="w3-bar-item w3-button">Talks</a>-->
    <a href="#publications" class="w3-bar-item w3-button">Publications</a>
    <a href="#services" class="w3-bar-item w3-button">Services</a>
    <a href="#educations" class="w3-bar-item w3-button">Educations</a>
    <a href="#awards" class="w3-bar-item w3-button">Awards</a>
    <a href="#resources" class="w3-bar-item w3-button">Resources</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-center w3-padding-24">

    Kaiqiang Wang

  </div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:80px"></div>

<!-- The Biography Section -->
    <div class="w3-container w3-padding-32" id="biography">
      <h2>Biography</h2>
        <p class="w3-left-align" style="line-height:200%">
<!--      <img style="width: 80%;max-width: 80px" alt="profile photo" src="images/kaiqiang.png">-->
<!--      <h1>Kaiqiang Wang</h1>-->
<!--        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:800px">-->
          <a href="https://kqwang.github.io/">Kaiqiang Wang</a> (王凯强) is now a postdoctoral fellow in the Lab of <a href="https://www.eee.hku.hk/~elam/">Prof. Edmund Y. Lam</a> at the University of Hong Kong.
          Before that, he did postdoctoral research in the Lab of <a href="https://www.lambcuhk.org/people/pi">Prof. Renjie Zhou</a> at the Chinese University of Hong Kong.
          He received his PhD at Northwestern Polytechnical University under the supervision of <a href="https://scholar.google.com/citations?user=i0cHhBQAAAAJ">Prof. Jianlin Zhao</a>, <a href="https://teacher.gdut.edu.cn/jiangleidi">Prof. Jianglei Di</a>, and <a href="https://www3.ntu.edu.sg/home/mkmqian/">Prof. Kemao Qian</a>.
          <br><br>He is an enthusiast for <strong>computational imaging</strong> and <strong>deep learning</strong>.
        </p>

        <p class="w3-center">
          <a style="color: #4682B4" href="mailto:kqwang.optics@gmail.com">Email</a> |
          <a style="color: #4682B4" href="https://github.com/kqwang">Github</a> |
          <a style="color: #4682B4" href="https://scholar.google.com/citations?user=K_TBJDUAAAAJ&hl">Google Scholar</a> |
          <a style="color: #4682B4" href="https://www.researchgate.net/profile/Kaiqiang-Wang-5">ResearchGate</a> |
          <a style="color: #4682B4" href="https://www.zhihu.com/people/AI.imaging">ZhiHu(知乎)</a>
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> 04/2024, an <strong><span style="color:FireBrick">invited talk</span></strong> is given at <a style="color: #4682B4" href="https://cd2024.piers.org/session.html?sid=S137">PIERS2024</a>.</li></p>
      <p><li> 01/2024, a <strong><span style="color:FireBrick">cover paper</span></strong> is published on <a style="color: #4682B4" href="https://doi.org/10.1038/s41377-023-01340-x">Light: Science and Applications</a>.</li></p>
      <p><li> 03/2023, continue working in Hong Kong at <a style="color: #4682B4" href="https://isl.eee.hku.hk/">ISL@HKU</a>.</li></p>
      <p><li> 07/2022, become Dr. Wang and start career from <a style="color: #4682B4" href="https://www.lambcuhk.org/">LAMB@CUHK</a>.</li></p>

  </div>



 <!-- The Publications Section -->
  <div class="w3-container   w3-padding-32" id="publications">
    <h2>Publications</h2>
      <p class="w3-left-align" style="line-height:200%">

      </p>

      <h4> Academic Journals:</h4>
      <ol>

        <p>
        <li><strong>On the use of deep learning for phase recovery</strong>
        <br>
        <a href="https://kqwang.github.io/">K. Wang</a>, L. Song, C. Wang, Z. Ren, G. Zhao, J. Dou, J. Di, G. Barbastathis, R. Zhou, J. Zhao, E. Lam
        <br>
        <em>Light: Science & Applications</em> 2024 | <a style="color: #4682B4" href="https://doi.org/10.1038/s41377-023-01340-x">paper</a> | <a style="color: #4682B4" href="https://github.com/kqwang/phase-recovery">code</a> |  <strong><span style="color:FireBrick">cover paper and 2024 editors' highlight</span></strong>
        <br>
        <strong>News:</strong> <a style="color: #4682B4" href="https://phys.org/news/2024-01-deep-phase-recovery.html">Phys.org</a> | <a style="color: #4682B4" href="https://www.eurekalert.org/news-releases/1030138">Eurekalert!</a> | <a style="color: #4682B4" href="https://www.azooptics.com/News.aspx?newsID=28547">Azooptics</a> | <a style="color: #4682B4" href="https://mp.weixin.qq.com/s/CJfAQ7DsBHWGcJE36V2uxQ">中国光学</a> | <a style="color: #4682B4" href="https://mp.weixin.qq.com/s/SCPb9moq5thO8u6YH02lZQ">LSA</a> | <a style="color: #4682B4" href="https://mp.weixin.qq.com/s/WDpECC6F3Im74wV6PaEcUg">CSOE</a>
        <br>
        <div style="height:150px;overflow-y:auto" class="w3-light-grey">
        <strong>Abstract:</strong> Phase recovery (PR) refers to calculating the phase of the light field from its intensity measurements. As exemplified from quantitative phase imaging and coherent diffraction imaging to adaptive optics, PR is essential for reconstructing the refractive index distribution or topography of an object and correcting the aberration of an imaging system. In recent years, deep learning (DL), often implemented through deep neural networks, has provided unprecedented support for computational imaging, leading to more efficient solutions for various PR problems. In this review, we first briefly introduce conventional methods for PR. Then, we review how DL provides support for PR from the following three stages, namely, pre-processing, in-processing, and post-processing. We also review how DL is used in phase image processing. Finally, we summarize the work in DL for PR and provide an outlook on how to better use DL to improve the reliability and efficiency of PR. Furthermore, we present a live-updating resource (<a style="color: #4682B4" href="https://github.com/kqwang/phase-recovery">https://github.com/kqwang/phase-recovery</a>) for readers to learn more about PR.</div>
        <br>
        <a href="https://www.nature.com/documents/Editor_highlight_2024-2_.jpg" target="_blank">
        <img src="images/Editor_highlight_2024-2.jpg" style="max-width: 50%; height: auto;">
        </a>
        <p>
        <li>Real-time phase measurement of optical vortex via digital holography
        <br>
        H. Qiu, X. Liu, <a href="https://kqwang.github.io/">K. Wang</a>, J. Dou, J. Di, and Y. Qin
        <br>
        <em>Frontiers in Physics</em> 2023 | <a style="color: #4682B4" href="https://doi.org/10.3389/fphy.2023.1190616">paper</a>
        </p>

        <p>
        <li><strong>Deep learning spatial phase unwrapping: a comparative review</strong>
        <br>
        <a href="https://kqwang.github.io/">K. Wang</a>, Q. Kemao, J. Di, and J. Zhao
        <br>
        <em>Advanced Photonics Nexus</em> 2022 | <a style="color: #4682B4" href="https://doi.org/10.1117/1.APN.1.1.014001">paper</a> | <a style="color: #4682B4" href="https://github.com/kqwang/Phase_unwrapping_by_U-Net">code</a> | <a style="color: #4682B4" href="https://www.researching.cn/articles/OJc3ee5c3ec89a4a1a">video</a> | <strong><span style="color:FireBrick">first article of this journal</span></strong>
        <br>
        <div style="height:150px;overflow-y:auto" class="w3-light-grey">
        <strong>Abstract:</strong> Phase unwrapping is an indispensable step for many optical imaging and metrology techniques. The rapid development of deep learning has brought ideas to phase unwrapping. In the past four years, various phase dataset generation methods and deep-learning-involved spatial phase unwrapping methods have emerged quickly. However, these methods were proposed and analyzed individually, using different strategies, neural networks, and datasets, and applied to different scenarios. It is thus necessary to do a detailed comparison of these deep-learning-involved methods and the traditional methods in the same context. We first divide the phase dataset generation methods into random matrix enlargement, Gauss matrix superposition, and Zernike polynomials superposition, and then divide the deep-learning-involved phase unwrapping methods into deep-learning-performed regression, deep-learning-performed wrap count, and deep-learning-assisted denoising. For the phase dataset generation methods, the richness of the datasets and the generalization capabilities of the trained networks are compared in detail. In addition, the deep-learning-involved methods are analyzed and compared with the traditional methods in ideal, noisy, discontinuous, and aliasing cases. Finally, we give suggestions on the best methods for different situations and propose the potential development direction for the dataset generation method, neural network structure, generalization ability enhancement, and neural network training strategy for the deep-learning-involved spatial phase unwrapping methods.</div>
        </p>

        <p>
        <li>Light-field focusing and modulation through scattering media based on dual-polarization-encoded digital optical phase conjugation
        <br>
        J. Dou, C. Ma, <a href="https://kqwang.github.io/">K. Wang</a>, J. Di, J. Zhang, and J. Zhao
        <br>
        <em>Optics Letters</em> 2022 | <a style="color: #4682B4" href="https://doi.org/10.3389/fphy.2023.1190616">paper</a>
        </p>

        <p>
        <li><strong>Deep learning wavefront sensing and aberration correction in atmospheric turbulence</strong>
        <br>
        <a href="https://kqwang.github.io/">K. Wang</a>, M. Zhang, J. Tang, L. Wang, L. Hu, X. Wu, W. Li, J. Di, G. Liu, and J. Zhao
        <br>
        <em>PhotoniX</em> 2021 | <a style="color: #4682B4" href="https://doi.org/10.1186/s43074-021-00030-4">paper</a>
        <br>
        <div style="height:150px;overflow-y:auto" class="w3-light-grey">
        <strong>Abstract:</strong> Deep learning neural networks are used for wavefront sensing and aberration correction in atmospheric turbulence without any wavefront sensor (i.e. reconstruction of the wavefront aberration phase from the distorted image of the object). We compared and found the characteristics of the direct and indirect reconstruction ways:(i) directly reconstructing the aberration phase; (ii) reconstructing the Zernike coefficients and then calculating the aberration phase. We verified the generalization ability and performance of the network for a single object and multiple objects. What's more, we verified the correction effect for a turbulence pool and the feasibility for a real atmospheric turbulence environment.</div>
        </p>

        <p>
        <li>RestoreNet-Plus: Image restoration via deep learning in optical synthetic aperture imaging system
        <br>
        J. Tang, J. Wu, <a href="https://kqwang.github.io/">K. Wang</a>, Z. Ren, X. Wu, L. Hu, J. Di, G. Liu, and J. Zhao
        <br>
        <em>Optics and Lasers in Engineering</em> 2021 | <a style="color: #4682B4" href="https://doi.org/10.1016/j.optlaseng.2021.106707">paper</a>
        </p>

        <p>
        <li>RestoreNet: a deep learning framework for image restoration in optical synthetic aperture imaging system
        <br>
        J. Tang, <a href="https://kqwang.github.io/">K. Wang</a>, Z. Ren, W. Zhang, X. Wu, J. Di, G. Liu, and J. Zhao
        <br>
        <em>Optics and Lasers in Engineering</em> 2021 | <a style="color: #4682B4" href="https://doi.org/10.1016/j.optlaseng.2020.106463">paper</a>
        </p>

        <p>
        <li>Research Progress in the Applications of Convolutional Neural Networks in Optical Information Processing
        <br>
        J. Di, J. Tang, J. Wu, <a href="https://kqwang.github.io/">K. Wang</a>, Z. Ren, M. Zhang, and J. Zhao
        <br>
        <em>Laser & Optoelectronics Progress</em> 2021 | <a style="color: #4682B4" href="http://dx.doi.org/10.3788/LOP202158.1600001">paper</a>
        </p>

        <p>
        <li>Quantitative phase imaging using deep learning-based holographic microscope
        <br>
        J. Di, J. Wu, <a href="https://kqwang.github.io/">K. Wang</a>, J. Tang, Y. Li, and J. Zhao
        <br>
        <em>Frontiers in Physics</em> 2021 | <a style="color: #4682B4" href="https://doi.org/10.3389/fphy.2021.651313">paper</a>
        </p>

        <p>
        <li>Sparse-view imaging of a fiber internal structure in holographic diffraction tomography via a convolutional neural network
        <br>
        J. Di, W. Han, S. Liu, <a href="https://kqwang.github.io/">K. Wang</a>, J. Tang, and J. Zhao
        <br>
        <em>Applied Optics</em> 2021 | <a style="color: #4682B4" href="https://doi.org/10.1364/AO.404276">paper</a>
        </p>

        <p>
        <li><strong>Transport of intensity equation from a single intensity image via deep learning</strong>
        <br>
        <a href="https://kqwang.github.io/">K. Wang</a>, Jianglei Di, Ying Li, Zhenbo Ren, Qian Kemao, Jianlin Zhao
        <br>
        <em>Optics and Lasers in Engineering</em> 2020 | <a style="color: #4682B4" href="https://doi.org/10.1016/j.optlaseng.2020.106233">paper</a>
        <br>
        <div style="height:150px;overflow-y:auto" class="w3-light-grey">
        <strong>Abstract:</strong> The transport of intensity equation (TIE) is an ideal candidate for phase imaging with partially coherent illuminations. TIE has the advantages of simplicity in phase calculation due to its closed-form solution and no requirement for a reference beam and phase unwrapping due to its non-interferometric nature. However, TIE requires multiple through-focus intensity images, and is very sensitive to image boundaries and noise. Thus, in this paper, we combine deep learning with TIE, abbreviated as dTIE. After being trained by TIE phase results, the dTIE retains the advantages of TIE, and overcomes the shortcomings of TIE as follows: (i) only one de-focus intensity image is required for phase imaging while the result is very close to the TIE result with SSIM index reaches 0.95, enabling more efficient phase imaging; (ii) the boundary problem automatically disappears due to the translation invariance of the convolutional networks; (iii) it is insensitive to noise even with very heavy noise. All these enhancements are verified in the application of dTIE for phase imaging of real cells.</div>
        </p>

        <p>
        <li><strong>Y4-Net: a deep learning solution to one-shot dual-wavelength digital holographic reconstruction</strong>
        <br>
        <a href="https://kqwang.github.io/">K. Wang</a>, Q. Kemao, J. Di, and J. Zhao
        <br>
        <em>Optics Letters</em> 2020 | <a style="color: #4682B4" href="https://doi.org/10.1364/OL.395445">paper</a>
        <br>
        <div style="height:150px;overflow-y:auto" class="w3-light-grey">
        <strong>Abstract:</strong> In this Letter, a deep learning solution (Y4-Net, four output channels network) to one-shot dual-wavelength digital holography is proposed to simultaneously reconstruct the complex amplitude information of both wavelengths from a single digital hologram with high efficiency. In the meantime, by using single-wavelength results as network ground truth to train the Y4-Net, the challenging spectral overlapping problem in common-path situations is solved with high accuracy.</div>
        </p>


        <p>
        <li>A deep learning-based image restoration method in optical synthetic aperture imaging system
        <br>
        J. Tang, <a href="https://kqwang.github.io/">K. Wang</a>, W. Zhang, X. Wu, G. Liu, J. Di, and J. Zhao
        <br>
        <em>Acta Optica Sinica</em> 2020 | <a style="color: #4682B4" href="http://dx.doi.org/10.3788/AOS202040.2111001">paper</a>
        </p>

        <p>
        <li>Classification of cell morphology with quantitative phase microscopy and machine learning
        <br>
        Y. Li, J. Di, <a href="https://kqwang.github.io/">K. Wang</a>, S. Wang, and J. Zhao
        <br>
        <em>Optics Express</em> 2020 | <a style="color: #4682B4" href="https://doi.org/10.1364/OE.397029">paper</a>
        </p>

        <p>
        <li><strong>Y-Net: a one-to-two deep learning framework for digital holographic reconstruction</strong>
        <br>
        <a href="https://kqwang.github.io/">K. Wang</a>, J. Dou, Q. Kemao, J. Di, and J. Zhao
        <br>
        <em>Optics Letters</em> 2019 | <a style="color: #4682B4" href="https://doi.org/10.1364/OL.44.004765">paper</a> | <strong><span style="color:FireBrick">editors' pick </span></strong>
        <br>
        <div style="height:150px;overflow-y:auto" class="w3-light-grey">
        <strong>Abstract:</strong> In this Letter, for the first time, to the best of our knowledge, we propose a digital holographic reconstruction method with a one-to-two deep learning framework (Y-Net). Perfectly fitting the holographic reconstruction process, the Y-Net can simultaneously reconstruct intensity and phase information from a single digital hologram. As a result, this compact network with reduced parameters brings higher performance than typical network variants. The experimental results of the mouse phagocytes demonstrate the advantages of the proposed Y-Net.</div>
        </p>

        <p>
        <li><strong>One-step robust deep learning phase unwrapping</strong>
        <br>
        <a href="https://kqwang.github.io/">K. Wang</a>, Y. Li, Q. Kemao, J. Di, and J. Zhao
        <br>
        <em>Optics express</em> 2019 | <a style="color: #4682B4" href="https://doi.org/10.1364/OE.27.015100">paper</a> | <a style="color: #4682B4" href="https://github.com/kqwang/Phase_unwrapping_by_U-Net">code</a> | <strong><span style="color:FireBrick">ESI highly cited paper </span></strong>
        <br>
        <div style="height:150px;overflow-y:auto" class="w3-light-grey">
        <strong>Abstract:</strong> Phase unwrapping is an important but challenging issue in phase measurement. Even with the research efforts of a few decades, unfortunately, the problem remains not well solved, especially when heavy noise and aliasing (undersampling) are present. We propose a database generation method for phase-type objects and a one-step deep learning phase unwrapping method. With a trained deep neural network, the unseen phase fields of living mouse osteoblasts and dynamic candle flame are successfully unwrapped, demonstrating that the complicated nonlinear phase unwrapping task can be directly fulfilled in one step by a single deep neural network. Excellent anti-noise and anti-aliasing performances outperforming classical methods are highlighted in this paper.</div>
        </p>

        <p>
        <li>Quantitative phase microscopy for cellular dynamics based on transport of intensity equation
        <br>
        Y. Li, J. Di, C. Ma, J. Zhang, J. Zhong, <a href="https://kqwang.github.io/">K. Wang</a>, T. Xi, and J. Zhao
        <br>
        <em>Optics Express</em> 2018 | <a style="color: #4682B4" href="https://doi.org/10.1364/OE.26.000586">paper</a>
        </p>

        <p>
        <li>Quasicommon-path digital holographic microscopy with phase aberration compensation based on a long-working distance objective
        <br>
        J. Di, <a href="https://kqwang.github.io/">K. Wang</a>, J. Zhang, C. Ma, T. Xi, Y. Li, K. Wei, W. Qu, and J. Zhao
        <br>
        <em>Optical Engineering</em> 2018 | <a style="color: #4682B4" href="https://doi.org/10.1117/1.OE.57.2.024108">paper</a>
        </p>

        <p>
        <li>Quantitative and dynamic phase imaging of biological cells by the use of the digital holographic microscopy based on a beam displacer unit
        <br>
        J. Di, Y. Li, <a href="https://kqwang.github.io/">K. Wang</a>, and J. Zhao
        <br>
        <em>IEEE Photonics Journal</em> 2018 | <a style="color: #4682B4" href="https://doi.org/10.1109/JPHOT.2018.2839878">paper</a>
        </p>

        <p>
        <li>Dual-wavelength common-path digital holographic microscopy for quantitative phase imaging of biological cells
        <br>
        J. Di, Y. Song, T. Xi, J. Zhang, Y. Li, C. Ma, <a href="https://kqwang.github.io/">K. Wang</a>, and J. Zhao
        <br>
        <em>Optical Engineering</em> 2017 | <a style="color: #4682B4" href="https://doi.org/10.1117/1.OE.56.11.111712">paper</a>
        </p>

      </ol>

      <h4> Conference Proceedings: </h4>
      <ol>
        <p>
        <li>RestoreNet: a deep learning framework for image restoration in optical multi-aperture imaging system
        <br>
        J. Tang, <a href="https://kqwang.github.io/">K. Wang</a>, X. Wu, J. Di, G. Liu, and J. Zhao
        <br>
        in Optics Frontier Online 2020: Optics Imaging and Display (SPIE, 2020), 11571, pp. 19–25. | <a style="color: #4682B4" href="https://doi.org/10.1117/12.2576299">paper</a>
        </p>

        <p>
        <li>Deep learning in computational imaging
        <br>
        J. Di, <a href="https://kqwang.github.io/">K. Wang</a>, and J. Zhao
        <br>
        in Holography, Diffractive Optics, and Applications X (SPIE, 2020), 11551, p. 1155107. | <a style="color: #4682B4" href="https://doi.org/10.1117/12.2573707">paper</a>
        </p>

        <p>
        <li>Deep learning-based holographic reconstruction in digital holography
        <br>
        J. Di, <a href="https://kqwang.github.io/">K. Wang</a>, Y. Li, and J. Zhao
        <br>
        in Digital Holography and Three-Dimensional Imaging (Optica Publishing Group, 2020), pp. HTu4B-2. | <a style="color: #4682B4" href="https://doi.org/10.1364/DH.2020.HTu4B.2">paper</a>
        </p>

        <p>
        <li>Common-path digital holographic microscopy based on a beam displacer unit
        <br>
        J. Di, J. Zhang, Y. Song, <a href="https://kqwang.github.io/">K. Wang</a>, K. Wei, and J. Zhao
        <br>
        in Quantitative Phase Imaging IV (SPIE, 2018), 10503, pp. 208–211. | <a style="color: #4682B4" href="https://doi.org/10.1117/12.2289324">paper</a>
        </p>

        <p>
        <li>Improvement of phase measurement accuracy and stability in dual-wavelength common-path digital holographic microscopy
        <br>
        J. Di, Y. Song, T. Xi, J. Zhang, Y. Li, C. Ma, <a href="https://kqwang.github.io/">K. Wang</a>, and J. Zhao
        <br>
        in Fifth International Conference on Optical and Photonics Engineering (SPIE, 2017), 10449, pp. 349–354. | <a style="color: #4682B4" href="https://doi.org/10.1117/12.2270774">paper</a>
        </p>

      </ol>
    </p>
  </div>



<!--&lt;!&ndash; The Services Section &ndash;&gt;-->
<!--  <div class="w3-container w3-light-grey w3-padding-32" id="service">-->
<!--    <h2>Services</h2>-->
<!--      <p><li> </p>-->
<!--  </div>-->



<!-- The Services Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="services">
    <h2>Services</h2>
    <h4> Journal Reviewer: </h4>
    <strong>Nature</strong>: Light: Science & Applications.
    <br>
    <br>
    <strong>IEEE</strong>: IEEE Transactions on Image Processing, IEEE Photonics Technology Letters,
IEEE Photonics Journal.
    <br>
    <br>
    <strong>Optica</strong>: Biomedical Optics Express, Optics Express, Applied Optics, Journal of the Optical Society
of America A, Optics Continuum.
    <br>
    <br>
    <strong>Elsevier</strong>: Optics and Lasers in Engineering, Optics Communications.
  </div>


<!-- The Educations Section -->
  <div class="w3-container w3-padding-32" id="educations">
    <h2>Educations</h2>
      <li><em>2016-2022</em>, Northwestern Polytechnical University, Xi'an, China.
      <br>
      PhD, Optical Engineering</li>
      <br>
      <li><em>2012-2016</em>, Northwestern Polytechnical University, Xi'an, China.
      <br>
      BSc, Applied Physics
      </li>

  </div>

  <!-- The awards Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="awards">
    <h2>Awards</h2>
      <p>
      <li> He was awarded the honor of <em>Three Good Student</em> and the <em>Excellent Young Pioneer</em> at the student period.

      </p>
      </li>
  </div>

    <!-- The Resources Section -->
  <div class="w3-container  w3-padding-32" id="resources">
    <h2>Resources</h2>
      <p>
        <ol>
          <p>
          <a style="color: #4682B4" href="https://github.com/kqwang/phase-recovery">Resource for phase recovery</a>.
          </p>

          <p>
          <a style="color: #4682B4" href="https://github.com/kqwang/computational-imaging">Resource for computational imaging</a>.
          </p>

        </ol>
      </p>
      </li>
  </div>

<!-- Default Statcounter code for https://kqwang.github.io/
https://kqwang.github.io/ -->
<script type="text/javascript">
var sc_project=12887075;
var sc_invisible=1;
var sc_security="6599b468";
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - Statcounter" href="https://statcounter.com/"
target="_blank"><img class="statcounter"
src="https://c.statcounter.com/12887075/0/6599b468/1/"
alt="Web Analytics Made Easy - Statcounter"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->

<!-- End page content -->


<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
